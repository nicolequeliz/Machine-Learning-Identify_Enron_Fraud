{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Identify Fraud From Enron Email**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The project uses the dataset from the Enron fraud case to create a predicitive model using machine learning algorithms to help pin point which employees could be a person of interest in the investigation based on financial and email records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import precision_score \n",
    "from sklearn.metrics import recall_score \n",
    "\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "from tester import test_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are my feature selections. I origionally included all finacial features, 'poi', and a few of the emial features. As you can see some have been commented out and I will explain why I chose those a bit later in the report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi','salary', 'deferral_payments', \n",
    "                 'total_payments', 'loan_advances', \n",
    "                 'bonus', 'restricted_stock_deferred', \n",
    "                 'deferred_income', 'total_stock_value', \n",
    "                 'expenses', \n",
    "                 'exercised_stock_options', \n",
    "                 'long_term_incentive', \n",
    "                 'restricted_stock',\n",
    "                 'to_messages', \n",
    "                 'from_poi_to_this_person', 'from_messages',\n",
    "                 'from_this_person_to_poi'\n",
    "                 ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Exploration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I  will explore the dataset to get an idea of the data structure and what I was working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people: 146\n",
      "Number of features: 21\n",
      "Person of Interest count: 18\n",
      "POI percentage: 12.33 %\n",
      "Number of features used: 17\n"
     ]
    }
   ],
   "source": [
    "##Data Exploration\n",
    "#total number of data points\n",
    "total_people = len(data_dict.keys())\n",
    "\n",
    "print 'Number of people:', total_people\n",
    "print 'Number of features:',(len(data_dict.values()[0]))\n",
    "##Finding POIs in the Enron Data\n",
    "poi_count=0\n",
    "for x, y in data_dict.items():\n",
    "    if y['poi']==1:\n",
    "        poi_count+=1\n",
    "print 'Person of Interest count:', poi_count\n",
    "\n",
    "#Percent POI\n",
    "poi_perc = round((1.*poi_count/total_people)*100,2)\n",
    "print 'POI percentage:',poi_perc,\"%\"\n",
    "\n",
    "# # of features used\n",
    "feat_len = len(features_list)\n",
    "print 'Number of features used:', feat_len\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 146 observations with 23 features. Of the 145 observations, 23 are a 'Person of Interest', which amounted to 12.41% of observations as poi's. Of the 23 features, I chose to use 12 of them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I will check the data for outliers based on salary and bonus, and remove them is needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAERCAYAAACU1LsdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xca41438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Task 2: Remove outliers\n",
    "##check for outliers\n",
    "features = ['salary','bonus']\n",
    "data = featureFormat(data_dict, features)\n",
    "\n",
    "plt.scatter(data[:,0], data[:,1])\n",
    "plt.xlabel(\"salary\")\n",
    "plt.ylabel(\"bonus\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the scatter plot above, there are significant outliers that need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers left:\n",
      "[('SKILLING JEFFREY K', 1111258), ('LAY KENNETH L', 1072321), ('FREVERT MARK A', 1060932), ('PICKERING MARK R', 655037)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAEKCAYAAAC7c+rvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb9f70f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Remove\n",
    "data_dict.pop('TOTAL', 0)\n",
    "data = featureFormat(data_dict, features)\n",
    "\n",
    "person = [] \n",
    "for p in data_dict: \n",
    "     if data_dict[p]['salary'] != \"NaN\": \n",
    "         person.append((p, data_dict[p]['salary'])) \n",
    "print \"Outliers left:\" \n",
    "print sorted(person, key = lambda x: x[1], reverse=True)[0:4]\n",
    "\n",
    "plt.scatter(data[:,0], data[:,1])\n",
    "plt.xlabel(\"salary\")\n",
    "plt.ylabel(\"bonus\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the outliers, I was able to get a better view of the data. There were still a couple of outliers iddentified as Jefferey Skilling, Kenneth Lay, and Mark Frevert but I chose to keep due to the fact that they were top exectuives and most likely involved in the fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I create two new features that find a persons ratio of emails sent to and recieved from a person of interest. I believe these ratios would help see a person's interactions with a person of interest which may then reveal whether of not they themselves were involed in the fraud based on the level of activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['poi',\n",
       " 'salary',\n",
       " 'deferral_payments',\n",
       " 'total_payments',\n",
       " 'loan_advances',\n",
       " 'bonus',\n",
       " 'restricted_stock_deferred',\n",
       " 'deferred_income',\n",
       " 'total_stock_value',\n",
       " 'expenses',\n",
       " 'exercised_stock_options',\n",
       " 'long_term_incentive',\n",
       " 'restricted_stock',\n",
       " 'to_messages',\n",
       " 'from_poi_to_this_person',\n",
       " 'from_messages',\n",
       " 'from_this_person_to_poi',\n",
       " 'to_poi_perc',\n",
       " 'from_poi_perc']"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Task 3: Create new feature(s)\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "for p in my_dataset:\n",
    "    from_poi = my_dataset[p]['from_poi_to_this_person']\n",
    "    total_to_msg = my_dataset[p]['to_messages']\n",
    "    if from_poi != 'NaN' and total_to_msg !='NaN':\n",
    "        my_dataset[p]['from_poi_perc'] = (1.*from_poi/total_to_msg)*100\n",
    "    else:\n",
    "        my_dataset[p]['from_poi_perc'] = 0\n",
    "        \n",
    "for p in my_dataset:\n",
    "    to_poi = my_dataset[p]['from_this_person_to_poi']\n",
    "    total_from_msg = my_dataset[p]['from_messages']\n",
    "    if to_poi != 'NaN' and total_from_msg !='NaN':\n",
    "        my_dataset[p]['to_poi_perc'] = (1.*to_poi/total_from_msg)*100\n",
    "    else:\n",
    "        my_dataset[p]['to_poi_perc'] = 0\n",
    "\n",
    "features_list = features_list + ['to_poi_perc']+['from_poi_perc']\n",
    "features_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have added to new features to the features list. After running SelectKBest, shown below, the new feature 'to_poi_perc' was selected as one of the best features and will make a significant impact on final recall and precision score which is seen at the end of the report. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Extract features and labels from dataset for local testing\n",
    "my_dataset = data_dict\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier in the report I mentioned that I would explain why I chose to comment out certain features. My reasoning is based on the algorithm I ran below. I tested a number of different k values starting with the default of 10. \n",
    "Precision and Recall based on k-value:\n",
    "\n",
    "k = 10: p = 0.32 , r = 0.31\n",
    "\n",
    "k = 9: p = 0.40, r = 0.31\n",
    "\n",
    "k = 8: p = 0.48, r = 0.39\n",
    "\n",
    "k = 7: p = 0.48, r = 0.37\n",
    "\n",
    "k = 6: p = 0.51, r = 0.38\n",
    "\n",
    "k = 5: p = 0.48, r = 0.38\n",
    "\n",
    "k = 4: p = 0.49, r = 0.32\n",
    "\n",
    "K with a value of 5 gives the highest, balanced precision and recall and so that is I the value I will use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best features:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('exercised_stock_options', 25.097541528735491),\n",
       " ('total_stock_value', 24.467654047526398),\n",
       " ('bonus', 21.060001707536571),\n",
       " ('salary', 18.575703268041785),\n",
       " ('to_poi_perc', 16.641707070469028),\n",
       " ('deferred_income', 11.595547659730601),\n",
       " ('long_term_incentive', 10.072454529369441)]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_list = ['poi',\n",
    " 'salary',\n",
    " 'deferral_payments',\n",
    " 'total_payments',\n",
    " 'loan_advances',\n",
    " 'bonus',\n",
    " 'restricted_stock_deferred',\n",
    " 'deferred_income',\n",
    " 'total_stock_value',\n",
    " 'expenses',\n",
    " 'exercised_stock_options',\n",
    " 'long_term_incentive',\n",
    " 'restricted_stock',\n",
    " 'to_messages',\n",
    " 'from_poi_to_this_person',\n",
    " 'from_messages',\n",
    " 'from_this_person_to_poi',\n",
    " 'to_poi_perc',\n",
    " 'from_poi_perc']\n",
    "from sklearn.feature_selection import f_classif, SelectKBest \n",
    "k = 7\n",
    "selector = SelectKBest(f_classif, k) \n",
    "selector.fit_transform(features, labels) \n",
    "print \"Best features:\"\n",
    "scores = zip(features_list[1:],selector.scores_)\n",
    "scores_sorted = sorted(scores, key = lambda x: x[1], reverse=True  )\n",
    "#scores_sorted\n",
    "best_features = scores_sorted[:k]\n",
    "best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimze my features chosen, I used the SelectKBest algorithm to identify the top seven best features in the dataset. Based off of the output, I adjusted the features I orgionally chose to use the optimal ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Final set of features\n",
    "features_list = ['poi','salary', #'deferral_payments', \n",
    "                 #'total_payments', \n",
    "                 #'loan_advances', \n",
    "                 'bonus', #'restricted_stock_deferred', \n",
    "                 'deferred_income', \n",
    "                 'total_stock_value', \n",
    "                 #'expenses', \n",
    "                 'exercised_stock_options',\n",
    "                 'long_term_incentive',\n",
    "                 #'restricted_stock',\n",
    "                 #'to_messages', \n",
    "                 #'from_poi_to_this_person', 'from_messages',\n",
    "                 #'from_this_person_to_poi'\n",
    "                 'to_poi_perc'\n",
    "                 #'from_poi_perc'\n",
    "                 ]\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation is a procoess of model performance evaluation. The purpose of it is to make sure the machine learning algorithm is doing whta you want it to do and to also use a test dataset to understand how the model performs on unseen data. There are a few different strategies to validate the model. One of them is to split the available data into train and test data another one is to perform a cross validation: process of splitting the data on k beans equal size and run learning experiments, and repeat this step mutliple times and take the average test result.\n",
    "I will be using Kfold to split the data. In K-fold cross validation, it splits the training data into k parts, or folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use KFold for split and validate algorithm \n",
    "from sklearn.cross_validation import KFold \n",
    "kf=KFold(len(labels),3) \n",
    "for train_indices, test_indices in kf: \n",
    "    #make training and testing sets \n",
    "    features_train= [features[ii] for ii in train_indices] \n",
    "    features_test= [features[ii] for ii in test_indices] \n",
    "    labels_train=[labels[ii] for ii in train_indices] \n",
    "    labels_test=[labels[ii] for ii in test_indices] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classifiers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have chosen to use the Naive Bayes and Decision Tree algorithms as classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy: 0.8958\n",
      "Naive Bayes time: 0.016 s\n"
     ]
    }
   ],
   "source": [
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "\n",
    "##Naive Bayes\n",
    "from time import time\n",
    "t0 = time() \n",
    " \n",
    "clf = GaussianNB() \n",
    "clf.fit(features_train, labels_train) \n",
    "pred = clf.predict(features_test) \n",
    "accuracy = accuracy_score(pred,labels_test) \n",
    "print 'Naive Bayes accuracy:',round(accuracy,4) \n",
    " \n",
    "print 'Naive Bayes time:', round((time()-t0), 3), \"s\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy: 0.8125\n",
      "Decision Tree time: 0.0 s\n"
     ]
    }
   ],
   "source": [
    "##Decision Tree\n",
    "t0 = time() \n",
    "\n",
    "clf = tree.DecisionTreeClassifier() \n",
    "clf.fit(features_train,labels_train) \n",
    "pred = clf.predict(features_test)\n",
    "accuracy = accuracy_score(labels_test, pred)  \n",
    "print 'Decision Tree accuracy:', round(accuracy,4)\n",
    " \n",
    "print 'Decision Tree time:', round((time()-t0), 3), \"s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to use the algorithms Naive Bayes and Decision Tree. Naive Bayes gave the best accuracy with 89% while Decision Tree only gave around 81% accuracy. In the next section I will tune the Decision Tree with hopes that it will increase the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Scaling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling is important for alogrithms that are based on distance between features, such as SVM. Decision Tree does not utilize distance between features and threfore no scaling was done. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm tuning is a final step in the process of applied machine learning before presenting results. Tuning is a key part to optimizing an algorithm. Tuning an algorithm or machine learning technique, can be simply thought of as process which one goes through in which they optimize the parameters that impact the model in order to enable the algorithm to perform the best. If not done properly it can result in overfitting or generalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Tuning 1:\n",
      "Accuracy: 0.875\n",
      "Decision Tree time: 0.0 s\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.80214\tPrecision: 0.27874\tRecall: 0.24250\tF1: 0.25936\tF2: 0.24897\n",
      "\tTotal predictions: 14000\tTrue positives:  485\tFalse positives: 1255\tFalse negatives: 1515\tTrue negatives: 10745\n",
      "\n",
      "\n",
      "Decision Tree Tuning 2:\n",
      "Accuracy: 0.875\n",
      "Decision Tree time: 0.0 s\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=15, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.82100\tPrecision: 0.34108\tRecall: 0.27150\tF1: 0.30234\tF2: 0.28305\n",
      "\tTotal predictions: 14000\tTrue positives:  543\tFalse positives: 1049\tFalse negatives: 1457\tTrue negatives: 10951\n",
      "\n",
      "\n",
      "Decision Tree Tuning 1:\n",
      "Accuracy: 0.8542\n",
      "Decision Tree time: 0.0 s\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.82064\tPrecision: 0.27763\tRecall: 0.15950\tF1: 0.20260\tF2: 0.17434\n",
      "\tTotal predictions: 14000\tTrue positives:  319\tFalse positives:  830\tFalse negatives: 1681\tTrue negatives: 11170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script. \n",
    "\n",
    "##Tuning\n",
    "##Min_Sample_split = 5\n",
    "t0 = time() \n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=5) \n",
    "clf = clf.fit(features_train,labels_train) \n",
    "pred= clf.predict(features_test) \n",
    "accuracy = accuracy_score(labels_test, pred)\n",
    "print 'Decision Tree Tuning 1:'\n",
    "print 'Accuracy:', round(accuracy,4)\n",
    "print 'Decision Tree time:', round((time()-t0), 3), \"s\"\n",
    "test_classifier(clf, my_dataset, features_list)\n",
    "\n",
    "\n",
    "##Min_Sample_split = 10\n",
    "t0 = time() \n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=15) \n",
    "clf = clf.fit(features_train,labels_train) \n",
    "pred= clf.predict(features_test) \n",
    "accuracy = accuracy_score(labels_test, pred)\n",
    "print '\\nDecision Tree Tuning 2:'\n",
    "print 'Accuracy:', round(accuracy,4)\n",
    "print 'Decision Tree time:', round((time()-t0), 3), \"s\"\n",
    "test_classifier(clf, my_dataset, features_list)\n",
    "\n",
    "##Min_Sample_split = 15\n",
    "t0 = time() \n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=30) \n",
    "clf = clf.fit(features_train,labels_train) \n",
    "pred= clf.predict(features_test) \n",
    "accuracy = accuracy_score(labels_test, pred)\n",
    "print '\\nDecision Tree Tuning 1:'\n",
    "print 'Accuracy:', round(accuracy,4)\n",
    "print 'Decision Tree time:', round((time()-t0), 3), \"s\"\n",
    "test_classifier(clf, my_dataset, features_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tuned the algorithm by adjusting 'min_sample_split' 3 different ways, 5, 15, and 30. Setting min sample split to 30 resulted in the best accuracy. However, min sample split with a value of 10 resulted in the highest precision and recall scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with the tuning, Decision Tree's accuracy was still lower than Naive Bayes and so I have chosen Naive Bayes as my final algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Algorithm NB:\n",
      "Naive Bayes accuracy: 0.895833333333\n",
      "time: 0.0 s.\n",
      "Precision :  0.5\n",
      "Recall: 0.6\n"
     ]
    }
   ],
   "source": [
    "##Final Algorithm\n",
    "t0 = time()\n",
    "clf = GaussianNB() \n",
    "clf.fit(features_train, labels_train) \n",
    "pred = clf.predict(features_test) \n",
    "accuracy = accuracy_score(pred,labels_test)\n",
    "\n",
    "print '\\nFinal Algorithm NB:'\n",
    "print 'Naive Bayes accuracy:',accuracy\n",
    "\n",
    "print \"time:\", round((time() - t0),3), \"s.\"\n",
    "\n",
    "\n",
    "##Precision\n",
    "print 'Precision : ', precision_score(labels_test,pred)\n",
    "\n",
    "##Recall\n",
    "print 'Recall:', recall_score(labels_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes' final accuracy was 89% with a presicion score of 0.5 and recall of score of 0.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\tAccuracy: 0.85436\tPrecision: 0.48748\tRecall: 0.37950\tF1: 0.42676\tF2: 0.39709\n",
      "\tTotal predictions: 14000\tTrue positives:  759\tFalse positives:  798\tFalse negatives: 1241\tTrue negatives: 11202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "### check your results. You do not need to change anything below, but make sure\n",
    "### that the version of poi_id.py that you submit can be run on its own and\n",
    "### generates the necessary .pkl files for validating your results.\n",
    "test_classifier(clf, my_dataset, features_list)\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After identifying and removing the outliers I was able to get a better visualization of the data anc chose to create two new features that would help gage a person's interactions with a poi and in turn help identify whether that perosn should be a poi themselves or not. The features the ratio of how many times a person emailed a poi out of the total emails sent and the other created the ratio of how many time a person was emailed by a poi out of the total number of emails recieved. After testing both Naive Bayes and Decision Tree classifiers, I found that Naive Bayes had better accuracy even after tuning the Decision Tree parameters. \n",
    "Using Naive Bayes I was be consistently get a presicion score of around 0.48 and a recall score of 0.38. In this case the accuracy score would not be a good evaluation metric due to the fact that the information is not balanced. Only 12% of the observations were 'poi' and so the best evaluation metrics for this kind of data are precision score and recall score. The precision score(tp/(tp+fp)) indicates how often a poi was correctly classified. It is intuitively the ability of the classifier not to label as positive a sample that is negative. While the recall (tp/(tp+fn)) score is how often the classifier will label any given observation as a poi. In other words, the ability of the classifier to find all the positive samples. \n",
    "I think that this analysis is a good starting point in identifying poi but there is only so much inforamtion you extract by interpreting financial and email information in numerical form. A good next step would be to apply text learning to really dig into the content of those emails. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**References**\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\n",
    "http://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
